{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5101f5a2",
   "metadata": {},
   "source": [
    "# Contextual Bayesian Optimisation via Large Language Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d590f50",
   "metadata": {},
   "source": [
    "This notebook will incorporate Part 1 and compare variations of BO-LIFT via the tell-predict phase.\n",
    "\n",
    "\n",
    "**NOTE:** Before running this file, you must fix the relative import issues - all you must do is remove the full stop from in front of the imports. Until the directory is cleaned, this has to be done if you want to run the code in the notebook. If you do not, you may run the test files instead."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1589ed6b",
   "metadata": {},
   "source": [
    "<DIV STYLE=\"background-color:#000000; height:10px; width:100%;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0b774b",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe06c92",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-13T13:57:28.705339522Z",
     "start_time": "2023-07-13T13:57:28.658785593Z"
    }
   },
   "outputs": [],
   "source": [
    "# Standard Library\n",
    "import os\n",
    "import itertools\n",
    "import pickle\n",
    "\n",
    "# Third Party\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Private\n",
    "from model import CEBO\n",
    "from bo_lift import AskTellFewShotTopk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913e27a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-13T12:13:56.759964371Z",
     "start_time": "2023-07-13T12:13:56.749792570Z"
    }
   },
   "outputs": [],
   "source": [
    "# Default OpenAI API Key\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b067b4",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebf92c9",
   "metadata": {},
   "source": [
    "The original paper used data corresponding to this paper [ESOL](https://www.researchgate.net/publication/8551133_ESOL_Estimating_Aqueous_Solubility_Directly_from_Molecular_Structure) - this corresponds to only 927 examples with 7 columns, with only 3 being important. This is not enough information for us to compare alternative techniques, hence we will use the larger dataset, provided from Kaggle, which incorporates more information about these molecules [AqSOL](https://www.kaggle.com/datasets/sorkun/aqsoldb-a-curated-aqueous-solubility-dataset?resource=download)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb00f7e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-13T12:13:57.530780284Z",
     "start_time": "2023-07-13T12:13:57.468726130Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load AqSolDB data\n",
    "aqsoldb_df = pd.read_csv(\"data/aqsoldb.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcc9abe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-13T12:13:57.698832864Z",
     "start_time": "2023-07-13T12:13:57.636552597Z"
    }
   },
   "outputs": [],
   "source": [
    "# Clean data\n",
    "aqsoldb_df = aqsoldb_df.dropna()\n",
    "aqsoldb_df = aqsoldb_df.drop_duplicates().reset_index(drop=True)\n",
    "aqsoldb_df.rename(columns={'Name': 'Compound ID'}, inplace=True)\n",
    "aqsoldb_df = aqsoldb_df.drop([\"ID\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d72f47",
   "metadata": {},
   "source": [
    "Given the token length of the OpenAI language models, we will work with chemical compounds which have a length of less than 15."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8656e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-13T12:13:58.065281094Z",
     "start_time": "2023-07-13T12:13:58.023029098Z"
    }
   },
   "outputs": [],
   "source": [
    "# Keep compounds that \"read\" easily\n",
    "aqsoldb_df = aqsoldb_df[aqsoldb_df[\"Compound ID\"].str.len()<15].reset_index(drop=True)\n",
    "aqsoldb_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62c6112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a smaller dataset framework\n",
    "mini_df = aqsoldb_df.sample(n=1000, random_state=42).reset_index(drop=True)\n",
    "mini_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a1812a",
   "metadata": {},
   "source": [
    "# Tell-Predict Experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5f5daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ablation_study(T_list, k_list, train_num_list, test_num_list, models_list, data):\n",
    "    # Store results\n",
    "    bo_lift_results = []\n",
    "    cebo_lift_results_1 = []\n",
    "    cebo_lift_results_2 = []\n",
    "    cebo_lift_results_3 = []\n",
    "    cebo_lift_results_4 = []\n",
    "    cebo_lift_results_5 = []\n",
    "    # Loop\n",
    "    print(\"Ablation study commenced!\")\n",
    "    for T, k, num_train, num_test, model in itertools.product(T_list, k_list, train_num_list, test_num_list,\n",
    "                                                                   models_list):\n",
    "        print(f\"T = {T} | k = {k} | num_train = {num_train} | num_test = {num_test} | model = {model}\")\n",
    "        bo_lift_result = []\n",
    "        cebo_lift_result_1 = []\n",
    "        cebo_lift_result_2 = []\n",
    "        cebo_lift_result_3 = []\n",
    "        cebo_lift_result_4 = []\n",
    "        cebo_lift_result_5 = []\n",
    "        for i in range(10):\n",
    "            # Create data\n",
    "            shuffled_df = data.sample(frac=1)\n",
    "            train_df = shuffled_df.iloc[:num_train]\n",
    "            test_df = shuffled_df.iloc[num_train:].head(num_test)\n",
    "            # Create the model object\n",
    "            bo_lift = AskTellFewShotTopk(x_formatter=lambda x: f\"compound id {x}\",\n",
    "                                         y_name=\"solubility\",\n",
    "                                         y_formatter=lambda y: f\"{y:.6f}\",\n",
    "                                         model=model,\n",
    "                                         selector_k=k,\n",
    "                                         temperature=0.7)\n",
    "            cebo_lift_1 = AskTellFewShotTopk(x_formatter=lambda x: f\"compound id {x}\",\n",
    "                                             y_name=\"solubility\",\n",
    "                                             y_formatter=lambda y: f\"{y:.6f}\",\n",
    "                                             model=model,\n",
    "                                             selector_k=k,\n",
    "                                             temperature=T,\n",
    "                                             prefix=(f\"You are an expert chemist. \"\n",
    "                                                     \"The following are correctly answered questions. \"\n",
    "                                                     \"Each answer is numeric and ends with ###\\n\"))\n",
    "            cebo_lift_2 = CEBO(y_name=\"solubility\",\n",
    "                               model=model,\n",
    "                               selector_k=k,\n",
    "                               temperature=T,\n",
    "                               domain=None,\n",
    "                               features=True)\n",
    "            cebo_lift_3 = CEBO(y_name=\"solubility\",\n",
    "                               model=model,\n",
    "                               selector_k=k,\n",
    "                               temperature=T,\n",
    "                               domain=\"chemist\",\n",
    "                               features=True)\n",
    "            cebo_lift_4 = CEBO(y_name=\"solubility\",\n",
    "                               model=model,\n",
    "                               selector_k=k,\n",
    "                               temperature=T,\n",
    "                               domain=None,\n",
    "                               features=True)\n",
    "            cebo_lift_5 = CEBO(y_name=\"solubility\",\n",
    "                               model=model,\n",
    "                               selector_k=k,\n",
    "                               temperature=T,\n",
    "                               domain=\"chemist\",\n",
    "                               features=True)\n",
    "            # Tell some points to the model\n",
    "            for _, row in train_df.iterrows():\n",
    "                bo_lift.tell(row[\"Compound ID\"], row[\"Solubility\"])\n",
    "                cebo_lift_1.tell(row[\"Compound ID\"], row[\"Solubility\"])\n",
    "                cebo_lift_2.tell(row[[\"Compound ID\", \"MolLogP\", \"MolMR\", \"Solubility\"]].to_dict())\n",
    "                cebo_lift_3.tell(row[[\"Compound ID\", \"MolLogP\", \"MolMR\", \"Solubility\"]].to_dict())\n",
    "                cebo_lift_4.tell(row[[\"Compound ID\", \"Ocurrences\", \"SD\", \"Solubility\"]].to_dict())\n",
    "                cebo_lift_5.tell(row[[\"Compound ID\", \"Ocurrences\", \"SD\", \"Solubility\"]].to_dict())\n",
    "            # Predict remaining points\n",
    "            bo_lift_y_pred = [bo_lift.predict(row[\"Compound ID\"]) for _, row in test_df.iterrows()]\n",
    "            cebo_lift_y_pred_1 = [cebo_lift_1.predict(row[\"Compound ID\"]) for _, row in test_df.iterrows()]\n",
    "            cebo_lift_y_pred_2 = [cebo_lift_2.predict(row[[\"Compound ID\", \"MolLogP\", \"MolMR\"]].to_dict()) for _, row\n",
    "                                  in test_df.iterrows()]\n",
    "            cebo_lift_y_pred_3 = [cebo_lift_3.predict(row[[\"Compound ID\", \"MolLogP\", \"MolMR\"]].to_dict()) for _, row\n",
    "                                  in test_df.iterrows()]\n",
    "            cebo_lift_y_pred_4 = [cebo_lift_4.predict(row[[\"Compound ID\", \"Ocurrences\", \"SD\"]].to_dict()) for _, row\n",
    "                                  in test_df.iterrows()]\n",
    "            cebo_lift_y_pred_5 = [cebo_lift_5.predict(row[[\"Compound ID\", \"Ocurrences\", \"SD\"]].to_dict()) for _, row\n",
    "                                  in test_df.iterrows()]\n",
    "            # Modify results\n",
    "            bo_lift_y_pred_modify = [sol.mean() if len(sol) >= 1 else np.nan for sol in bo_lift_y_pred]\n",
    "            cebo_lift_y_pred_modify_1 = [sol.mean() if len(sol) >= 1 else np.nan for sol in cebo_lift_y_pred_1]\n",
    "            cebo_lift_y_pred_modify_2 = [sol.mean() if len(sol) >= 1 else np.nan for sol in cebo_lift_y_pred_2]\n",
    "            cebo_lift_y_pred_modify_3 = [sol.mean() if len(sol) >= 1 else np.nan for sol in cebo_lift_y_pred_3]\n",
    "            cebo_lift_y_pred_modify_4 = [sol.mean() if len(sol) >= 1 else np.nan for sol in cebo_lift_y_pred_4]\n",
    "            cebo_lift_y_pred_modify_5 = [sol.mean() if len(sol) >= 1 else np.nan for sol in cebo_lift_y_pred_5]\n",
    "            # Store values\n",
    "            bo_lift_result.append({\"Iteration\": i,\n",
    "                                   \"T\": T,\n",
    "                                   \"k\": k,\n",
    "                                   \"Train\": num_train,\n",
    "                                   \"Test\": num_test,\n",
    "                                   \"Model\": model,\n",
    "                                   \"True\": list(test_df[\"Solubility\"]),\n",
    "                                   \"Predictions\": bo_lift_y_pred_modify\n",
    "                                   })\n",
    "            cebo_lift_result_1.append({\"Iteration\": i,\n",
    "                                       \"T\": T,\n",
    "                                       \"k\": k,\n",
    "                                       \"Train\": num_train,\n",
    "                                       \"Test\": num_test,\n",
    "                                       \"Model\": model,\n",
    "                                       \"True\": list(test_df[\"Solubility\"]),\n",
    "                                       \"Predictions\": cebo_lift_y_pred_modify_1\n",
    "                                       })\n",
    "            cebo_lift_result_2.append({\"Iteration\": i,\n",
    "                                       \"T\": T,\n",
    "                                       \"k\": k,\n",
    "                                       \"Train\": num_train,\n",
    "                                       \"Test\": num_test,\n",
    "                                       \"Model\": model,\n",
    "                                       \"True\": list(test_df[\"Solubility\"]),\n",
    "                                       \"Predictions\": cebo_lift_y_pred_modify_2\n",
    "                                       })\n",
    "            cebo_lift_result_3.append({\"Iteration\": i,\n",
    "                                       \"T\": T,\n",
    "                                       \"k\": k,\n",
    "                                       \"Train\": num_train,\n",
    "                                       \"Test\": num_test,\n",
    "                                       \"Model\": model,\n",
    "                                       \"True\": list(test_df[\"Solubility\"]),\n",
    "                                       \"Predictions\": cebo_lift_y_pred_modify_3\n",
    "                                       })\n",
    "            cebo_lift_result_4.append({\"Iteration\": i,\n",
    "                                       \"T\": T,\n",
    "                                       \"k\": k,\n",
    "                                       \"Train\": num_train,\n",
    "                                       \"Test\": num_test,\n",
    "                                       \"Model\": model,\n",
    "                                       \"True\": list(test_df[\"Solubility\"]),\n",
    "                                       \"Predictions\": cebo_lift_y_pred_modify_4\n",
    "                                       })\n",
    "            cebo_lift_result_5.append({\"Iteration\": i,\n",
    "                                       \"T\": T,\n",
    "                                       \"k\": k,\n",
    "                                       \"Train\": num_train,\n",
    "                                       \"Test\": num_test,\n",
    "                                       \"Model\": model,\n",
    "                                       \"True\": list(test_df[\"Solubility\"]),\n",
    "                                       \"Predictions\": cebo_lift_y_pred_modify_5\n",
    "                                       })\n",
    "        # Add to final results\n",
    "        bo_lift_results.append(bo_lift_result)\n",
    "        cebo_lift_results_1.append(cebo_lift_result_1)\n",
    "        cebo_lift_results_2.append(cebo_lift_result_2)\n",
    "        cebo_lift_results_3.append(cebo_lift_result_3)\n",
    "        cebo_lift_results_4.append(cebo_lift_result_4)\n",
    "        cebo_lift_results_5.append(cebo_lift_result_5)\n",
    "        print(\"Sub-experiment complete!\")\n",
    "    # Combine the lists into a single data structure\n",
    "    pickle_data = (bo_lift_results, cebo_lift_results_1,\n",
    "                   cebo_lift_results_2, cebo_lift_results_3,\n",
    "                   cebo_lift_results_4, cebo_lift_results_5)\n",
    "    # Specify the file path where you want to save the pickled data (NOTE: Change this for own directory and rename when running it)\n",
    "    file_path = '/Users/siddarthanath/Documents/University-College-London/Thesis/cebo/results/tell-predict/ablation_study.pkl'\n",
    "    # Pickle and save the data\n",
    "    with open(file_path, 'wb') as file:\n",
    "        pickle.dump(pickle_data, file)\n",
    "    print(\"Ablation study completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da5ad48",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26b7c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "kwargs = {\"T_list\": [0.7],\n",
    "          \"k_list\": [5],\n",
    "          \"train_num_list\": [5, 25, 45],\n",
    "          \"test_num_list\": [15],\n",
    "          \"models_list\": [\"curie\", \"davinci\"],\n",
    "          \"data\": mini_df \n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9b52ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "ablation_study(**kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4940bf23",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0453f2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from the pickle file\n",
    "with open('./results/tell-predict/ablation_study.pkl', 'rb') as pickle_file:\n",
    "    loaded_data = pickle.load(pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d447c683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results\n",
    "full_results = {\"BO-LIFT\": loaded_data[0], \n",
    "                \"BO-LIFT+DOMAIN\": loaded_data[1],\n",
    "                \"CEBO-LIFT+NO_DOMAIN\": loaded_data[2],\n",
    "                \"CEBO-LIFT+DOMAIN+FEATURE_1\": loaded_data[3],\n",
    "                \"CEBO-LIFT+DOMAIN+FEATURE_2\": loaded_data[4],\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fe637e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store MSE results\n",
    "mse_results = {}\n",
    "for key, item in full_results.items():\n",
    "    # Results\n",
    "    sub_result = item\n",
    "    # Store results for each iterations\n",
    "    sub_experiment_results = {}\n",
    "    for i in range(len(sub_result)):\n",
    "        sub_experiment_mse_results = []\n",
    "        sub_experiment = sub_result[i]\n",
    "        # Loop through each iteration and calculate MSE\n",
    "        for j in range(len(sub_experiment)):\n",
    "            y_true = sub_experiment[j][\"True\"]\n",
    "            y_pred = sub_experiment[j][\"Predictions\"]\n",
    "            # Fill in empty or nan predictions - additionally, clip outliers as this will skew the MSE\n",
    "            for k in range(len(y_pred)):\n",
    "                if np.isnan(y_pred[k]):\n",
    "                    y_pred[k] = y_true[k]\n",
    "                elif np.abs(y_true[k] - y_pred[k]) > 100000:\n",
    "                    y_pred[k] = 0\n",
    "                else:\n",
    "                    y_pred[k] = y_pred[k]\n",
    "            y_true = [x for x, y in zip(y_true, y_pred) if y != 0]\n",
    "            y_pred = [y for y in y_pred if y != 0]\n",
    "            # Calculate MSE\n",
    "            mse = mean_squared_error(y_true=y_true, y_pred=y_pred)\n",
    "            # Store results\n",
    "            results = {\"Iteration\": j, \"T\": sub_experiment[j][\"T\"], \"k\": sub_experiment[j][\"k\"],\n",
    "                       \"Train\": sub_experiment[j][\"Train\"], \"Test\": sub_experiment[j][\"Test\"], \"Model\": sub_experiment[j][\"Model\"],\n",
    "                       \"MSE\": mse}\n",
    "            sub_experiment_mse_results.append(results)\n",
    "        # Put everything into one dictionary\n",
    "        final_mse_results = {\"T\": sub_experiment[j][\"T\"], \"k\": sub_experiment[j][\"k\"],\n",
    "        \"Train\": sub_experiment[j][\"Train\"], \"Test\": sub_experiment[j][\"Test\"], \"Model\": sub_experiment[j][\"Model\"],\n",
    "        \"MSE\": [experiment[\"MSE\"] for experiment in sub_experiment_mse_results]}\n",
    "        sub_experiment_results[i] = final_mse_results\n",
    "    # Store results\n",
    "    mse_results[key] = sub_experiment_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e1260f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data for plotting\n",
    "full_results_thesis = []  \n",
    "i = 0          \n",
    "for _, data in mse_results.items():\n",
    "    # Use log to scale results - since MSE values are above 1, this will not affect anything\n",
    "    mse_data = [item['MSE'] for _, item in data.items()]\n",
    "    T, k = data[i][\"T\"], data[i][\"k\"]\n",
    "    # Create a figure and axis\n",
    "    full_results_thesis.append([f\"T = {T} | k = {k} | Result = {np.round(np.log(np.mean(value)), 3)}Â±{np.round(np.log(np.std(value)), 3)}\" for value in mse_data])\n",
    "    i+=1\n",
    "full_results_thesis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65101cd",
   "metadata": {},
   "source": [
    "<DIV STYLE=\"background-color:#000000; height:10px; width:100%;\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msc-2023",
   "language": "python",
   "name": "msc-2023"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
